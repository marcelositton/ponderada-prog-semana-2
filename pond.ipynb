{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaebd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino: 25000 amostras | Teste: 25000 amostras\n",
      "Classes (0=neg,1=pos): [0 1] -> [12500 12500]\n",
      "Tamanho médio da review (treino): 238.7 tokens | mediana: 178.0\n",
      "Shape X_train: (25000, 20000) | X_test: (25000, 20000)\n",
      "Densidade média (treino): 0.006889\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,001</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │        \u001b[38;5;34m20,001\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,001</span> (78.13 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,001\u001b[0m (78.13 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,001</span> (78.13 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m20,001\u001b[0m (78.13 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2000/2000 - 7s - 4ms/step - accuracy: 0.8618 - f1_metric: 0.8445 - loss: 0.3930 - val_accuracy: 0.8916 - val_f1_metric: 0.8774 - val_loss: 0.3012\n",
      "Epoch 2/50\n",
      "2000/2000 - 3s - 2ms/step - accuracy: 0.9247 - f1_metric: 0.9154 - loss: 0.2346 - val_accuracy: 0.8956 - val_f1_metric: 0.8812 - val_loss: 0.2700\n",
      "Epoch 3/50\n",
      "2000/2000 - 3s - 2ms/step - accuracy: 0.9451 - f1_metric: 0.9387 - loss: 0.1825 - val_accuracy: 0.8968 - val_f1_metric: 0.8834 - val_loss: 0.2614\n",
      "Epoch 4/50\n",
      "2000/2000 - 4s - 2ms/step - accuracy: 0.9578 - f1_metric: 0.9524 - loss: 0.1495 - val_accuracy: 0.8974 - val_f1_metric: 0.8836 - val_loss: 0.2606\n",
      "Epoch 5/50\n",
      "2000/2000 - 3s - 2ms/step - accuracy: 0.9661 - f1_metric: 0.9616 - loss: 0.1255 - val_accuracy: 0.8960 - val_f1_metric: 0.8826 - val_loss: 0.2637\n",
      "Epoch 6/50\n",
      "2000/2000 - 4s - 2ms/step - accuracy: 0.9733 - f1_metric: 0.9692 - loss: 0.1070 - val_accuracy: 0.8952 - val_f1_metric: 0.8813 - val_loss: 0.2691\n",
      "Epoch 7/50\n",
      "2000/2000 - 3s - 2ms/step - accuracy: 0.9790 - f1_metric: 0.9757 - loss: 0.0922 - val_accuracy: 0.8952 - val_f1_metric: 0.8812 - val_loss: 0.2761\n",
      "Epoch 8/50\n",
      "2000/2000 - 3s - 2ms/step - accuracy: 0.9832 - f1_metric: 0.9803 - loss: 0.0801 - val_accuracy: 0.8940 - val_f1_metric: 0.8808 - val_loss: 0.2842\n",
      "Epoch 9/50\n",
      "2000/2000 - 4s - 2ms/step - accuracy: 0.9861 - f1_metric: 0.9839 - loss: 0.0700 - val_accuracy: 0.8920 - val_f1_metric: 0.8786 - val_loss: 0.2930\n",
      "Epoch 10/50\n",
      "2000/2000 - 5s - 2ms/step - accuracy: 0.9885 - f1_metric: 0.9867 - loss: 0.0614 - val_accuracy: 0.8916 - val_f1_metric: 0.8790 - val_loss: 0.3024\n",
      "Epoch 11/50\n",
      "2000/2000 - 4s - 2ms/step - accuracy: 0.9905 - f1_metric: 0.9890 - loss: 0.0541 - val_accuracy: 0.8904 - val_f1_metric: 0.8775 - val_loss: 0.3123\n",
      "Epoch 12/50\n",
      "2000/2000 - 4s - 2ms/step - accuracy: 0.9922 - f1_metric: 0.9907 - loss: 0.0478 - val_accuracy: 0.8876 - val_f1_metric: 0.8752 - val_loss: 0.3225\n",
      "Epoch 13/50\n",
      "2000/2000 - 4s - 2ms/step - accuracy: 0.9935 - f1_metric: 0.9920 - loss: 0.0423 - val_accuracy: 0.8864 - val_f1_metric: 0.8737 - val_loss: 0.3330\n",
      "Epoch 14/50\n",
      "2000/2000 - 4s - 2ms/step - accuracy: 0.9942 - f1_metric: 0.9930 - loss: 0.0375 - val_accuracy: 0.8846 - val_f1_metric: 0.8712 - val_loss: 0.3438\n",
      "Epoch 15/50\n",
      "2000/2000 - 6s - 3ms/step - accuracy: 0.9955 - f1_metric: 0.9943 - loss: 0.0333 - val_accuracy: 0.8842 - val_f1_metric: 0.8706 - val_loss: 0.3549\n",
      "Epoch 16/50\n",
      "2000/2000 - 7s - 3ms/step - accuracy: 0.9963 - f1_metric: 0.9952 - loss: 0.0297 - val_accuracy: 0.8832 - val_f1_metric: 0.8698 - val_loss: 0.3661\n",
      "Epoch 17/50\n",
      "2000/2000 - 138s - 69ms/step - accuracy: 0.9969 - f1_metric: 0.9960 - loss: 0.0264 - val_accuracy: 0.8812 - val_f1_metric: 0.8675 - val_loss: 0.3774\n",
      "Epoch 18/50\n",
      "2000/2000 - 5s - 3ms/step - accuracy: 0.9976 - f1_metric: 0.9967 - loss: 0.0236 - val_accuracy: 0.8814 - val_f1_metric: 0.8676 - val_loss: 0.3889\n",
      "Epoch 19/50\n",
      "2000/2000 - 7s - 4ms/step - accuracy: 0.9983 - f1_metric: 0.9974 - loss: 0.0210 - val_accuracy: 0.8790 - val_f1_metric: 0.8649 - val_loss: 0.4005\n",
      "Epoch 20/50\n",
      "2000/2000 - 7s - 3ms/step - accuracy: 0.9987 - f1_metric: 0.9979 - loss: 0.0188 - val_accuracy: 0.8784 - val_f1_metric: 0.8637 - val_loss: 0.4123\n",
      "Epoch 21/50\n",
      "2000/2000 - 7s - 4ms/step - accuracy: 0.9989 - f1_metric: 0.9982 - loss: 0.0168 - val_accuracy: 0.8774 - val_f1_metric: 0.8622 - val_loss: 0.4242\n",
      "Epoch 22/50\n",
      "2000/2000 - 7s - 3ms/step - accuracy: 0.9991 - f1_metric: 0.9984 - loss: 0.0150 - val_accuracy: 0.8774 - val_f1_metric: 0.8624 - val_loss: 0.4362\n",
      "Epoch 23/50\n",
      "2000/2000 - 7s - 3ms/step - accuracy: 0.9992 - f1_metric: 0.9986 - loss: 0.0134 - val_accuracy: 0.8768 - val_f1_metric: 0.8607 - val_loss: 0.4483\n",
      "Epoch 24/50\n",
      "2000/2000 - 7s - 3ms/step - accuracy: 0.9993 - f1_metric: 0.9987 - loss: 0.0120 - val_accuracy: 0.8748 - val_f1_metric: 0.8581 - val_loss: 0.4606\n",
      "Epoch 25/50\n",
      "2000/2000 - 7s - 3ms/step - accuracy: 0.9995 - f1_metric: 0.9989 - loss: 0.0107 - val_accuracy: 0.8742 - val_f1_metric: 0.8575 - val_loss: 0.4729\n",
      "Epoch 26/50\n",
      "2000/2000 - 7s - 3ms/step - accuracy: 0.9996 - f1_metric: 0.9991 - loss: 0.0096 - val_accuracy: 0.8742 - val_f1_metric: 0.8574 - val_loss: 0.4854\n",
      "Epoch 27/50\n",
      "2000/2000 - 7s - 3ms/step - accuracy: 0.9997 - f1_metric: 0.9991 - loss: 0.0086 - val_accuracy: 0.8732 - val_f1_metric: 0.8562 - val_loss: 0.4980\n",
      "Epoch 28/50\n",
      "2000/2000 - 7s - 3ms/step - accuracy: 0.9997 - f1_metric: 0.9992 - loss: 0.0077 - val_accuracy: 0.8726 - val_f1_metric: 0.8554 - val_loss: 0.5107\n",
      "Epoch 29/50\n",
      "2000/2000 - 7s - 3ms/step - accuracy: 0.9998 - f1_metric: 0.9993 - loss: 0.0069 - val_accuracy: 0.8720 - val_f1_metric: 0.8547 - val_loss: 0.5235\n",
      "Epoch 30/50\n",
      "2000/2000 - 7s - 3ms/step - accuracy: 0.9998 - f1_metric: 0.9994 - loss: 0.0061 - val_accuracy: 0.8718 - val_f1_metric: 0.8545 - val_loss: 0.5364\n",
      "Epoch 31/50\n",
      "2000/2000 - 7s - 3ms/step - accuracy: 0.9999 - f1_metric: 0.9995 - loss: 0.0055 - val_accuracy: 0.8720 - val_f1_metric: 0.8546 - val_loss: 0.5493\n",
      "Epoch 32/50\n",
      "2000/2000 - 7s - 3ms/step - accuracy: 0.9999 - f1_metric: 0.9995 - loss: 0.0049 - val_accuracy: 0.8714 - val_f1_metric: 0.8539 - val_loss: 0.5624\n",
      "Epoch 33/50\n",
      "2000/2000 - 7s - 3ms/step - accuracy: 1.0000 - f1_metric: 0.9995 - loss: 0.0044 - val_accuracy: 0.8710 - val_f1_metric: 0.8530 - val_loss: 0.5755\n",
      "Epoch 34/50\n",
      "2000/2000 - 7s - 3ms/step - accuracy: 1.0000 - f1_metric: 0.9995 - loss: 0.0039 - val_accuracy: 0.8700 - val_f1_metric: 0.8520 - val_loss: 0.5886\n",
      "Epoch 35/50\n",
      "2000/2000 - 7s - 3ms/step - accuracy: 1.0000 - f1_metric: 0.9995 - loss: 0.0035 - val_accuracy: 0.8694 - val_f1_metric: 0.8513 - val_loss: 0.6019\n",
      "Epoch 36/50\n",
      "2000/2000 - 7s - 3ms/step - accuracy: 1.0000 - f1_metric: 0.9995 - loss: 0.0032 - val_accuracy: 0.8694 - val_f1_metric: 0.8514 - val_loss: 0.6151\n",
      "Epoch 37/50\n",
      "2000/2000 - 7s - 3ms/step - accuracy: 1.0000 - f1_metric: 0.9995 - loss: 0.0028 - val_accuracy: 0.8680 - val_f1_metric: 0.8499 - val_loss: 0.6285\n",
      "Epoch 38/50\n",
      "2000/2000 - 7s - 3ms/step - accuracy: 1.0000 - f1_metric: 0.9995 - loss: 0.0025 - val_accuracy: 0.8678 - val_f1_metric: 0.8495 - val_loss: 0.6419\n",
      "Epoch 39/50\n",
      "2000/2000 - 7s - 3ms/step - accuracy: 1.0000 - f1_metric: 0.9995 - loss: 0.0023 - val_accuracy: 0.8676 - val_f1_metric: 0.8492 - val_loss: 0.6553\n",
      "Epoch 40/50\n",
      "2000/2000 - 7s - 3ms/step - accuracy: 1.0000 - f1_metric: 0.9995 - loss: 0.0020 - val_accuracy: 0.8672 - val_f1_metric: 0.8489 - val_loss: 0.6688\n",
      "Epoch 41/50\n",
      "2000/2000 - 7s - 3ms/step - accuracy: 1.0000 - f1_metric: 0.9995 - loss: 0.0018 - val_accuracy: 0.8656 - val_f1_metric: 0.8474 - val_loss: 0.6824\n",
      "Epoch 42/50\n",
      "2000/2000 - 7s - 3ms/step - accuracy: 1.0000 - f1_metric: 0.9995 - loss: 0.0016 - val_accuracy: 0.8654 - val_f1_metric: 0.8471 - val_loss: 0.6960\n",
      "Epoch 43/50\n",
      "2000/2000 - 7s - 3ms/step - accuracy: 1.0000 - f1_metric: 0.9995 - loss: 0.0015 - val_accuracy: 0.8652 - val_f1_metric: 0.8470 - val_loss: 0.7096\n",
      "Epoch 44/50\n",
      "2000/2000 - 7s - 3ms/step - accuracy: 1.0000 - f1_metric: 0.9995 - loss: 0.0013 - val_accuracy: 0.8650 - val_f1_metric: 0.8468 - val_loss: 0.7232\n",
      "Epoch 45/50\n",
      "2000/2000 - 7s - 3ms/step - accuracy: 1.0000 - f1_metric: 0.9995 - loss: 0.0012 - val_accuracy: 0.8640 - val_f1_metric: 0.8458 - val_loss: 0.7369\n",
      "Epoch 46/50\n",
      "2000/2000 - 1694s - 847ms/step - accuracy: 1.0000 - f1_metric: 0.9995 - loss: 0.0011 - val_accuracy: 0.8636 - val_f1_metric: 0.8456 - val_loss: 0.7506\n",
      "Epoch 47/50\n",
      "2000/2000 - 22837s - 11s/step - accuracy: 1.0000 - f1_metric: 0.9995 - loss: 9.5265e-04 - val_accuracy: 0.8638 - val_f1_metric: 0.8459 - val_loss: 0.7643\n",
      "Epoch 48/50\n",
      "2000/2000 - 5s - 3ms/step - accuracy: 1.0000 - f1_metric: 0.9995 - loss: 8.5509e-04 - val_accuracy: 0.8626 - val_f1_metric: 0.8445 - val_loss: 0.7781\n",
      "Epoch 49/50\n",
      "2000/2000 - 56830s - 28s/step - accuracy: 1.0000 - f1_metric: 0.9995 - loss: 7.6768e-04 - val_accuracy: 0.8626 - val_f1_metric: 0.8443 - val_loss: 0.7918\n",
      "Epoch 50/50\n",
      "2000/2000 - 10s - 5ms/step - accuracy: 1.0000 - f1_metric: 0.9995 - loss: 6.8934e-04 - val_accuracy: 0.8622 - val_f1_metric: 0.8439 - val_loss: 0.8056\n",
      "\n",
      "[Evaluate] Métricas no conjunto de teste (Keras):\n",
      "Loss: 0.9328 | Accuracy: 0.8439 | F1: 0.8369\n",
      "\n",
      "[Métricas sklearn no teste]:\n",
      "Accuracy: 0.8439 | F1: 0.8415\n",
      "\n",
      "Matriz de confusão:\n",
      "[[10733  1767]\n",
      " [ 2136 10364]]\n",
      "\n",
      "Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8340    0.8586    0.8462     12500\n",
      "           1     0.8543    0.8291    0.8415     12500\n",
      "\n",
      "    accuracy                         0.8439     25000\n",
      "   macro avg     0.8442    0.8439    0.8438     25000\n",
      "weighted avg     0.8442    0.8439    0.8438     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Objetivo: Treinar um Perceptron (uma camada Dense com 1 neurônio + sigmoid)\n",
    "# no dataset IMDb para classificar reviews como negativas (0) ou positivas (1).\n",
    "\n",
    "# dataset escolhido (IMDb - já vem no Keras):\n",
    "# - Tarefa: classificação binária de sentimento.\n",
    "# - Tamanho: ~25.000 amostras de treino e ~25.000 de teste.\n",
    "# - transformação dos textos em números: usei Bag-of-Words multihot com\n",
    "#   as 20.000 palavras mais frequentes (dimensão = 20.000). Cada review vira\n",
    "#   um vetor 0/1 indicando se a palavra apareceu.\n",
    "\n",
    "# O que cada parte do treinamento faz:\n",
    "# - Camada Dense(1, sigmoid): é o “perceptron”.\n",
    "# - Loss = binary_crossentropy: mede o erro entre as probabilidades previstas (0 e 1)\n",
    "#    rótulos 0/1 =perda padrão para classificação binária.\n",
    "# - Otimizador = adam: ajusta os pesos usando gradiente com taxas adaptativas.\n",
    "# - Métricas: accuracy (proporção acertos) e F1 (média precisão e recall).\n",
    "#   No F1, binarizo as probabilidades com threshold 0,5.\n",
    "# - Treinamento: 50 épocas, batch_size=10, separando 20% do treino para validação.\n",
    "\n",
    "# Interpretaçãoo dos resultados:\n",
    "# - Accuracy de treino costuma chegar perto de 1; o modelo aprende bem os padrões lineares.\n",
    "# - Val_accuracy e val_f1 por volta de 0,88–0,90 são resultados condizentes para BoW + Perceptron.\n",
    "# - Às vezes a val_loss sobe enquanto val_accuracy/val_f1 ficam estáveis: pode indicar  overfitting leve.\n",
    "# - Possíveis melhorias :\n",
    "#   * adicionar regularização L2 na Dense;\n",
    "#   * usar EarlyStopping monitorando val_f1 e restaurar os melhores pesos;\n",
    "#   * ajustar o threshold para maximizar o F1 na validação;\n",
    "#   * trocar multihot por TF-IDF\n",
    "#Segue o Código:\n",
    "#-----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "import random\n",
    "\n",
    "# Reprodutibilidade\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# Carregar IMDb e mostrar estatísticas básicas do conjunto\n",
    "num_words = 20000  # tamanho do vocabulário BoW\n",
    "(x_train_seq, y_train), (x_test_seq, y_test) = keras.datasets.imdb.load_data(num_words=num_words)\n",
    "\n",
    "print(f\"Treino: {len(x_train_seq)} amostras | Teste: {len(x_test_seq)} amostras\")\n",
    "classes, counts = np.unique(y_train, return_counts=True)\n",
    "print(f\"Classes (0=neg,1=pos): {classes} -> {counts}\")\n",
    "\n",
    "lens = list(map(len, x_train_seq))\n",
    "print(f\"Tamanho médio da review (treino): {np.mean(lens):.1f} tokens | mediana: {np.median(lens)}\")\n",
    "\n",
    "# Vetorização: Bag-of-Words multihot (1 se a palavra aparece na review, 0 se não)\n",
    "def vectorize_sequences(seqs, dimension):\n",
    "    X = np.zeros((len(seqs), dimension), dtype=\"float32\")\n",
    "    for i, s in enumerate(seqs):\n",
    "        X[i, s] = 1.0\n",
    "    return X\n",
    "\n",
    "X_train = vectorize_sequences(x_train_seq, num_words)\n",
    "X_test  = vectorize_sequences(x_test_seq,  num_words)\n",
    "\n",
    "print(f\"Shape X_train: {X_train.shape} | X_test: {X_test.shape}\")\n",
    "print(f\"Densidade média (treino): {X_train.mean():.6f}\")\n",
    "\n",
    "# Métrica F1 personalizada\n",
    "@tf.function\n",
    "def f1_metric(y_true, y_pred):\n",
    "    y_true = tf.cast(tf.reshape(y_true, [-1]), tf.float32)\n",
    "    y_pred = tf.cast(tf.reshape(y_pred, [-1]), tf.float32)\n",
    "    y_pred_bin = tf.cast(y_pred >= 0.5, tf.float32)\n",
    "\n",
    "    tp = tf.reduce_sum(y_true * y_pred_bin)\n",
    "    fp = tf.reduce_sum((1.0 - y_true) * y_pred_bin)\n",
    "    fn = tf.reduce_sum(y_true * (1.0 - y_pred_bin))\n",
    "\n",
    "    precision = tp / (tp + fp + 1e-7)\n",
    "    recall    = tp / (tp + fn + 1e-7)\n",
    "    return 2.0 * precision * recall / (precision + recall + 1e-7)\n",
    "\n",
    "# Modelo Perceptron (1 neurônio com sigmoid)\n",
    "model = keras.Sequential([\n",
    "    keras.Input(shape=(num_words,)),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# Compilação do modelo\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\", f1_metric]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Treinamento\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=10,\n",
    "    validation_split=0.2,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Avaliação no teste e métricas adicionais\n",
    "print(\"\\n[Evaluate] Métricas no conjunto de teste (Keras):\")\n",
    "test_loss, test_acc, test_f1 = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Loss: {test_loss:.4f} | Accuracy: {test_acc:.4f} | F1: {test_f1:.4f}\")\n",
    "\n",
    "y_prob = model.predict(X_test, verbose=0).ravel()\n",
    "y_pred = (y_prob >= 0.5).astype(int)\n",
    "\n",
    "print(\"\\n[Métricas sklearn no teste]:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f} | F1: {f1_score(y_test, y_pred):.4f}\")\n",
    "\n",
    "print(\"\\nMatriz de confusão:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nRelatório de classificação:\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
