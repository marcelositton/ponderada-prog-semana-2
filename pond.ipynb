    "# Objetivo: Treinar um Perceptron (uma camada Dense com 1 neurônio + sigmoid)\n",
    "# no dataset IMDb para classificar reviews como negativas (0) ou positivas (1).\n",
    "\n",
    "# dataset escolhido (IMDb - já vem no Keras):\n",
    "# - Tarefa: classificação binária de sentimento.\n",
    "# - Tamanho: ~25.000 amostras de treino e ~25.000 de teste.\n",
    "# - transformação dos textos em números: usei Bag-of-Words multihot com\n",
    "#   as 20.000 palavras mais frequentes (dimensão = 20.000). Cada review vira\n",
    "#   um vetor 0/1 indicando se a palavra apareceu.\n",
    "\n",
    "# O que cada parte do treinamento faz:\n",
    "# - Camada Dense(1, sigmoid): é o “perceptron”.\n",
    "# - Loss = binary_crossentropy: mede o erro entre as probabilidades previstas (0 e 1)\n",
    "#    rótulos 0/1 =perda padrão para classificação binária.\n",
    "# - Otimizador = adam: ajusta os pesos usando gradiente com taxas adaptativas.\n",
    "# - Métricas: accuracy (proporção acertos) e F1 (média precisão e recall).\n",
    "#   No F1, binarizo as probabilidades com threshold 0,5.\n",
    "# - Treinamento: 50 épocas, batch_size=10, separando 20% do treino para validação.\n",
    "\n",
    "# Interpretaçãoo dos resultados:\n",
    "# - Accuracy de treino costuma chegar perto de 1; o modelo aprende bem os padrões lineares.\n",
    "# - Val_accuracy e val_f1 por volta de 0,88–0,90 são resultados condizentes para BoW + Perceptron.\n",
    "# - Às vezes a val_loss sobe enquanto val_accuracy/val_f1 ficam estáveis: pode indicar  overfitting leve.\n",
    "# - Possíveis melhorias :\n",
    "#   * adicionar regularização L2 na Dense;\n",
    "#   * usar EarlyStopping monitorando val_f1 e restaurar os melhores pesos;\n",
    "#   * ajustar o threshold para maximizar o F1 na validação;\n",
    "#   * trocar multihot por TF-IDF\n",
    "#Segue o Código:\n",
    "#-----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "import random\n",
    "\n",
    "# Reprodutibilidade\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# Carregar IMDb e mostrar estatísticas básicas do conjunto\n",
    "num_words = 20000  # tamanho do vocabulário BoW\n",
    "(x_train_seq, y_train), (x_test_seq, y_test) = keras.datasets.imdb.load_data(num_words=num_words)\n",
    "\n",
    "print(f\"Treino: {len(x_train_seq)} amostras | Teste: {len(x_test_seq)} amostras\")\n",
    "classes, counts = np.unique(y_train, return_counts=True)\n",
    "print(f\"Classes (0=neg,1=pos): {classes} -> {counts}\")\n",
    "\n",
    "lens = list(map(len, x_train_seq))\n",
    "print(f\"Tamanho médio da review (treino): {np.mean(lens):.1f} tokens | mediana: {np.median(lens)}\")\n",
    "\n",
    "# Vetorização: Bag-of-Words multihot (1 se a palavra aparece na review, 0 se não)\n",
    "def vectorize_sequences(seqs, dimension):\n",
    "    X = np.zeros((len(seqs), dimension), dtype=\"float32\")\n",
    "    for i, s in enumerate(seqs):\n",
    "        X[i, s] = 1.0\n",
    "    return X\n",
    "\n",
    "X_train = vectorize_sequences(x_train_seq, num_words)\n",
    "X_test  = vectorize_sequences(x_test_seq,  num_words)\n",
    "\n",
    "print(f\"Shape X_train: {X_train.shape} | X_test: {X_test.shape}\")\n",
    "print(f\"Densidade média (treino): {X_train.mean():.6f}\")\n",
    "\n",
    "# Métrica F1 personalizada\n",
    "@tf.function\n",
    "def f1_metric(y_true, y_pred):\n",
    "    y_true = tf.cast(tf.reshape(y_true, [-1]), tf.float32)\n",
    "    y_pred = tf.cast(tf.reshape(y_pred, [-1]), tf.float32)\n",
    "    y_pred_bin = tf.cast(y_pred >= 0.5, tf.float32)\n",
    "\n",
    "    tp = tf.reduce_sum(y_true * y_pred_bin)\n",
    "    fp = tf.reduce_sum((1.0 - y_true) * y_pred_bin)\n",
    "    fn = tf.reduce_sum(y_true * (1.0 - y_pred_bin))\n",
    "\n",
    "    precision = tp / (tp + fp + 1e-7)\n",
    "    recall    = tp / (tp + fn + 1e-7)\n",
    "    return 2.0 * precision * recall / (precision + recall + 1e-7)\n",
    "\n",
    "# Modelo Perceptron (1 neurônio com sigmoid)\n",
    "model = keras.Sequential([\n",
    "    keras.Input(shape=(num_words,)),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# Compilação do modelo\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\", f1_metric]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Treinamento\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=10,\n",
    "    validation_split=0.2,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Avaliação no teste e métricas adicionais\n",
    "print(\"\\n[Evaluate] Métricas no conjunto de teste (Keras):\")\n",
    "test_loss, test_acc, test_f1 = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Loss: {test_loss:.4f} | Accuracy: {test_acc:.4f} | F1: {test_f1:.4f}\")\n",
    "\n",
    "y_prob = model.predict(X_test, verbose=0).ravel()\n",
    "y_pred = (y_prob >= 0.5).astype(int)\n",
    "\n",
    "print(\"\\n[Métricas sklearn no teste]:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f} | F1: {f1_score(y_test, y_pred):.4f}\")\n",
    "\n",
    "print(\"\\nMatriz de confusão:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nRelatório de classificação:\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n"
